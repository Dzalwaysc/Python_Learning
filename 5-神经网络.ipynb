{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-5b712c761cc7>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/oliver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/oliver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/oliver/Desktop/mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/oliver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/oliver/Desktop/mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/oliver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /Users/oliver/Desktop/mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/oliver/Desktop/mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/oliver/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"/Users/oliver/Desktop/mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过操作符号变量来描述可交互的操作单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x不是一个特定的值，而是一个占位符placeholder\n",
    "# 我们在Tensorflow运行计算时输入这个值\n",
    "# 我们希望能够输入任何数量的MNIST图像\n",
    "# 每一张图展成784维的向量\n",
    "# 我们用2维的浮点数张量来表示这些图\n",
    "# 这个张量的形状是[None, 784]  (这里的None表示此张量的第一个维度可以是任何长度的)\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于权重和偏置量，tensorflow有更好的方法表示Variable\n",
    "# 一个Variable代表一个可修改的张量\n",
    "# 它们可以用于计算输入值，也可以在计算中被修改\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "B = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# W的维度是[784, 10]，因为我们想要用784维的图片向量乘以它\n",
    "# 用来得到一个10维的证据值向量\n",
    "# 每一位对应不同的数字类\n",
    "# b的形状是[10]，所以我们可以直接把它加到输出上面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + B)\n",
    "\n",
    "# 这里x是一个2维张量拥有多个输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义成本(cost)或者说损失(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float\", [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算交叉熵\n",
    "    $- \\sum y^{'} log(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))  \n",
    "# reduce表示降维的意思，在这里就是降维求和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播(backpropagation) 以及梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok，在上面我们已经设置好了我们的模型。\n",
    "在运算之前我们需要添加一个操作来初始化我们的创建变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一个Session里面启动我们的模型，并且初始化变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练模型，这里我们让模型循环训练1000次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000) :\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_:batch_ys})\n",
    "\n",
    "# 该循环的每个步骤中，我们都会随机抓去训练数据中的100个批处理数据点\n",
    "# 然后我们用这些数据点作为参数替换占位符来运行train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 那么我们模型的性能如何？\n",
    "- 首先需要让我们找出那些预测正确的标签\n",
    "- tf.argmax是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值\n",
    "- 然后我们可以用tf.equal来检测我们的预测是否于真实标签匹配（索引位置一样表示匹配）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "# 这行代码会给一组布尔值。\n",
    "# 为了确定正确预测项的比例\n",
    "# 我们可以把布尔值转换成浮点数，然后取平均值\n",
    "# 例如[True, False, True, True]会变成[1, 0, 1, 1]\n",
    "# 取得平均值后得到0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.argmax(input,dimension)  \n",
    "    - dimension = 0 按列找最大值\n",
    "    - dimension =1 按行找最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们计算所学习到的模型在测试数据集上面的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9178\n"
     ]
    }
   ],
   "source": [
    "print( sess.run(accuracy, feed_dict={x: mnist.test.images, y_:mnist.test.labels}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "- 权重和偏置初始化\n",
    "    - 权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度\n",
    "    - 由于我们使用的ReLU神经元，因此比较好的做法就是用一个较小的正数来初始化偏置项，避免神经元节点输出恒为0\n",
    "    - 为了不再建立模型的时候反复做初始化操作，我们定义了两个函数用于初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/oliver/Desktop/mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/oliver/Desktop/mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/oliver/Desktop/mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/oliver/Desktop/mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"/Users/oliver/Desktop/mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape) :\n",
    "    initial = tf.truncated_normal(shape, stddev=0)\n",
    "# tf.truncated_normal(shape, mean, stddev) \n",
    "# shape表示生成张量的维度，mean是均值，stddev是标准差\n",
    "# 这个函数产生正太分布，均值和标准差自己设定。\n",
    "# t输出如字面意思是截断的，而截断的标准是2倍的stddev。\n",
    "# 截断的意思就是举例，当输入参数mean = 0 ，stddev =1时，\n",
    "# 使用tf.truncated_normal的输出是不可能出现[-2,2]以外的点的，\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape) :\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "# 创建一个常数张量,传入list或者数值来填充\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 池化和卷机\n",
    "- tensorflow在卷积和池化上有很强的灵活性\n",
    "- 我们怎么处理边界？步长应该设多大？\n",
    "- 我们的卷积使用1步长(stride size)\n",
    "- 我们的卷积使用0边距(padding size)\n",
    "- 通过上述设定保证输出和输入时同一个大小\n",
    "- 我们的池化用简单传统的2x2大小的模版做max pooling\n",
    "- 为了代码更加简洁，我们把这部分抽象成一个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W) : \n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x) : \n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                                     strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一层卷机\n",
    "- 卷积在每个5x5的patch中算出32个特征\n",
    "- 卷积的权重张量形状时[5, 5, 1, 32]\n",
    "    - 前两个维度时patch的大小，接着是输入的通道数目，最后是输出的通道数目\n",
    "- 而对于每一个输出通道都有一个对应的偏置量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了用到这一层，我们把x变成一个4dimension向量\n",
    "# 其第2，3维对应图片的宽，高。\n",
    "# 最后一维对应图片的颜色通道数\n",
    "x_image = tf.reshape(x,[-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后我们把x_image和权值向量进行卷积，加上偏置项\n",
    "# 然后应用ReLU激活函数，最后进行max pooling\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二层卷机\n",
    "- 为了构建一个更深的网络，我们会把几个类似的层堆叠起来\n",
    "- 第二层中，每个5x5的patch会得到64个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 密集连接层\n",
    "- 现在，图片尺寸减小到7x7\n",
    "- 我们加入一个有1024个神经元的全连接层，用于处理整个图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们把池化层输出的张量reshape成一些向量\n",
    "# 乘上权重矩阵，加上偏置\n",
    "# 然后对其使用ReLU\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "- 为了减少过拟合，我们在输出层之前加入dropout。\n",
    "- 我们用一个placeholder来带遍一个神经元的输出在dropout中保持不变的概率\n",
    "- 这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow的tf.nn.dropout操作\n",
    "# 除了可以屏蔽神经元的输出外\n",
    "# 还会自动处理神经元输出值的scale\n",
    "# 所以用dropout的时候可以不用考虑scale\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出层\n",
    "- 最后我们添加一个softmax层，就像前面的单层softmax regression一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和评估模型\n",
    "- 为了进行训练和评估，我们使用与之前简单的单层softmax神经网络模型几乎相同的一套代码\n",
    "- 只是我们会用更加复杂的ADAM优化器来做梯度最速下降\n",
    "- 在feed_dict中加入额外的参数keep_prob来控制dropout比例\n",
    "- 最后每100次迭代输出一次日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0，training accuracy 0.18\n",
      "step 100，training accuracy 0.1\n",
      "step 200，training accuracy 0.08\n",
      "step 300，training accuracy 0.26\n",
      "step 400，training accuracy 0.6\n",
      "step 500，training accuracy 0.78\n",
      "step 600，training accuracy 0.78\n",
      "step 700，training accuracy 0.94\n",
      "step 800，training accuracy 0.94\n",
      "step 900，training accuracy 0.96\n",
      "step 1000，training accuracy 0.94\n",
      "step 1100，training accuracy 0.9\n",
      "step 1200，training accuracy 0.96\n",
      "step 1300，training accuracy 0.94\n",
      "step 1400，training accuracy 0.98\n",
      "step 1500，training accuracy 0.98\n",
      "step 1600，training accuracy 0.94\n",
      "step 1700，training accuracy 0.96\n",
      "step 1800，training accuracy 0.96\n",
      "step 1900，training accuracy 0.96\n",
      "step 2000，training accuracy 0.96\n",
      "step 2100，training accuracy 0.96\n",
      "step 2200，training accuracy 0.98\n",
      "step 2300，training accuracy 0.98\n",
      "step 2400，training accuracy 1\n",
      "step 2500，training accuracy 0.96\n",
      "step 2600，training accuracy 0.96\n",
      "step 2700，training accuracy 0.92\n",
      "step 2800，training accuracy 0.96\n",
      "step 2900，training accuracy 1\n",
      "step 3000，training accuracy 1\n",
      "step 3100，training accuracy 0.92\n",
      "step 3200，training accuracy 1\n",
      "step 3300，training accuracy 0.96\n",
      "step 3400，training accuracy 0.98\n",
      "step 3500，training accuracy 0.98\n",
      "step 3600，training accuracy 0.96\n",
      "step 3700，training accuracy 1\n",
      "step 3800，training accuracy 0.94\n",
      "step 3900，training accuracy 0.96\n",
      "step 4000，training accuracy 0.98\n",
      "step 4100，training accuracy 1\n",
      "step 4200，training accuracy 0.94\n",
      "step 4300，training accuracy 0.96\n",
      "step 4400，training accuracy 1\n",
      "step 4500，training accuracy 1\n",
      "step 4600，training accuracy 0.92\n",
      "step 4700，training accuracy 0.96\n",
      "step 4800，training accuracy 0.98\n",
      "step 4900，training accuracy 0.96\n",
      "step 5000，training accuracy 1\n",
      "step 5100，training accuracy 0.98\n",
      "step 5200，training accuracy 0.96\n",
      "step 5300，training accuracy 0.94\n",
      "step 5400，training accuracy 0.98\n",
      "step 5500，training accuracy 0.98\n",
      "step 5600，training accuracy 0.96\n",
      "step 5700，training accuracy 1\n",
      "step 5800，training accuracy 1\n",
      "step 5900，training accuracy 1\n",
      "step 6000，training accuracy 0.98\n",
      "step 6100，training accuracy 0.98\n",
      "step 6200，training accuracy 1\n",
      "step 6300，training accuracy 0.98\n",
      "step 6400，training accuracy 0.98\n",
      "step 6500，training accuracy 1\n",
      "step 6600，training accuracy 1\n",
      "step 6700，training accuracy 1\n",
      "step 6800，training accuracy 1\n",
      "step 6900，training accuracy 0.98\n",
      "step 7000，training accuracy 1\n",
      "step 7100，training accuracy 0.98\n",
      "step 7200，training accuracy 0.98\n",
      "step 7300，training accuracy 1\n",
      "step 7400，training accuracy 0.98\n",
      "step 7500，training accuracy 0.98\n",
      "step 7600，training accuracy 0.98\n",
      "step 7700，training accuracy 0.98\n",
      "step 7800，training accuracy 0.98\n",
      "step 7900，training accuracy 1\n",
      "step 8000，training accuracy 1\n",
      "step 8100，training accuracy 0.96\n",
      "step 8200，training accuracy 0.96\n",
      "step 8300，training accuracy 0.98\n",
      "step 8400，training accuracy 0.94\n",
      "step 8500，training accuracy 0.98\n",
      "step 8600，training accuracy 0.96\n",
      "step 8700，training accuracy 0.98\n",
      "step 8800，training accuracy 1\n",
      "step 8900，training accuracy 0.98\n",
      "step 9000，training accuracy 1\n",
      "step 9100，training accuracy 1\n",
      "step 9200，training accuracy 0.96\n",
      "step 9300，training accuracy 1\n",
      "step 9400，training accuracy 1\n",
      "step 9500，training accuracy 0.96\n",
      "step 9600，training accuracy 0.98\n",
      "step 9700，training accuracy 0.98\n",
      "step 9800，training accuracy 1\n",
      "step 9900，training accuracy 1\n",
      "step 10000，training accuracy 1\n",
      "step 10100，training accuracy 1\n",
      "step 10200，training accuracy 1\n",
      "step 10300，training accuracy 0.98\n",
      "step 10400，training accuracy 1\n",
      "step 10500，training accuracy 1\n",
      "step 10600，training accuracy 0.98\n",
      "step 10700，training accuracy 1\n",
      "step 10800，training accuracy 1\n",
      "step 10900，training accuracy 0.96\n",
      "step 11000，training accuracy 1\n",
      "step 11100，training accuracy 1\n",
      "step 11200，training accuracy 1\n",
      "step 11300，training accuracy 1\n",
      "step 11400，training accuracy 0.98\n",
      "step 11500，training accuracy 1\n",
      "step 11600，training accuracy 1\n",
      "step 11700，training accuracy 1\n",
      "step 11800，training accuracy 0.98\n",
      "step 11900，training accuracy 1\n",
      "step 12000，training accuracy 1\n",
      "step 12100，training accuracy 0.98\n",
      "step 12200，training accuracy 1\n",
      "step 12300，training accuracy 1\n",
      "step 12400，training accuracy 1\n",
      "step 12500，training accuracy 1\n",
      "step 12600，training accuracy 0.98\n",
      "step 12700，training accuracy 0.98\n",
      "step 12800，training accuracy 1\n",
      "step 12900，training accuracy 0.98\n",
      "step 13000，training accuracy 1\n",
      "step 13100，training accuracy 1\n",
      "step 13200，training accuracy 1\n",
      "step 13300，training accuracy 0.98\n",
      "step 13400，training accuracy 1\n",
      "step 13500，training accuracy 0.04\n",
      "step 13600，training accuracy 0.14\n",
      "step 13700，training accuracy 0.12\n",
      "step 13800，training accuracy 0.12\n",
      "step 13900，training accuracy 0.08\n",
      "step 14000，training accuracy 0.08\n",
      "step 14100，training accuracy 0.08\n",
      "step 14200，training accuracy 0.06\n",
      "step 14300，training accuracy 0.06\n",
      "step 14400，training accuracy 0.12\n",
      "step 14500，training accuracy 0.04\n",
      "step 14600，training accuracy 0.18\n",
      "step 14700，training accuracy 0.04\n",
      "step 14800，training accuracy 0.08\n",
      "step 14900，training accuracy 0.1\n",
      "step 15000，training accuracy 0.1\n",
      "step 15100，training accuracy 0.14\n",
      "step 15200，training accuracy 0.14\n",
      "step 15300，training accuracy 0.06\n",
      "step 15400，training accuracy 0.1\n",
      "step 15500，training accuracy 0.08\n",
      "step 15600，training accuracy 0.14\n",
      "step 15700，training accuracy 0.12\n",
      "step 15800，training accuracy 0.02\n",
      "step 15900，training accuracy 0.1\n",
      "step 16000，training accuracy 0.1\n",
      "step 16100，training accuracy 0.1\n",
      "step 16200，training accuracy 0.1\n",
      "step 16300，training accuracy 0.12\n",
      "step 16400，training accuracy 0.04\n",
      "step 16500，training accuracy 0.12\n",
      "step 16600，training accuracy 0.14\n",
      "step 16700，training accuracy 0.12\n",
      "step 16800，training accuracy 0.12\n",
      "step 16900，training accuracy 0.04\n",
      "step 17000，training accuracy 0.08\n",
      "step 17100，training accuracy 0.1\n",
      "step 17200，training accuracy 0.08\n",
      "step 17300，training accuracy 0.14\n",
      "step 17400，training accuracy 0.08\n",
      "step 17500，training accuracy 0.14\n",
      "step 17600，training accuracy 0.14\n",
      "step 17700，training accuracy 0.06\n",
      "step 17800，training accuracy 0.16\n",
      "step 17900，training accuracy 0.14\n",
      "step 18000，training accuracy 0.02\n",
      "step 18100，training accuracy 0.08\n",
      "step 18200，training accuracy 0.08\n",
      "step 18300，training accuracy 0.04\n",
      "step 18400，training accuracy 0.16\n",
      "step 18500，training accuracy 0.02\n",
      "step 18600，training accuracy 0.06\n",
      "step 18700，training accuracy 0.06\n",
      "step 18800，training accuracy 0.02\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20000) :\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i%100 == 0 : \n",
    "            train_accuracy = accuracy.eval(feed_dict={x : batch[0], y_ : batch[1], keep_prob : 1.0})\n",
    "            print(\"step %d，training accuracy %g\" % (i, train_accuracy))\n",
    "\n",
    "        train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})\n",
    "\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n",
    "        x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
